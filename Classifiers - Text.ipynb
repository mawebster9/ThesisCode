{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Text Values\n",
    "Michaela Webster - mawebster9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin anything, we need to import all of the libraries/functions that we will be using throughout our notebook. Pandas is a crucial part of this process since it houses our data. Another important feature of this process is the scikit-learn library - this library is our one-stop-shop for our machine learning needs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our data structure\n",
    "import pandas as pd\n",
    "\n",
    "#bag of words vectorizer - take inverse frequency of words to assign weights\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#split data into training/test data, validate our models, and specify number of folds for training/test data\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold \n",
    "\n",
    "# our 5 classification models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data and Set X & y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will focus solely on the judgment field. The judgment field acts like a brief story summary field that contains a lot of useful data surrounding a case. Our goal is to see if the judgment field can be used to determine whether a case should be denied or granted with high accuracy. For this, our X is the judgment field and its associated label, or y, is the denied field.\n",
    "\n",
    "Also note, we are reducing our number of entries to 500 since processing text data is very bulky. If done with all data, you would get a memory error. 500 records has enough data to make a reasonably accurate model but not too much where there is not enough memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to CSV file that contains our data\n",
    "path_to_file = \"https://raw.githubusercontent.com/mawebster9/ThesisCode/master/appeals_query.csv\"\n",
    "\n",
    "#open, read, and store our data into a pandas dataframe\n",
    "appeals_data = pd.read_csv(path_to_file, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign our attributes to X and y\n",
    "X = appeals_data['Judgment'].head(700)\n",
    "y = appeals_data['Denied']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Applicant's drug abuse was not mitigated where marijuana use was recent, and had continued after Applicant stated an intent to refrain from drug use in the future. He falsified his drug abuse history on security questionnaires in March and October 1995 an\""
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the first record in X to verify the previous step\n",
    "X.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the first record in y to verify the previous step\n",
    "y.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set-up X: Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data assigned to our X and y variables, it is time to prime the data for the machine learning algorithms. For text data, we need to break up the words in a way that a machine can understand the characteristics of speech. One of the ways we can do this is by using a bag of words. A bag of words essentially takes a large amount of text data and separates the values into separate words and counts the number of occurrences of each word. \n",
    "\n",
    "For this example, we will be using a vectorizer to split the words and calculate the number of occurrences for each word. The vectorizer we will use in this example, TfidfVectorizer, works by counting the inverse frequency of the words found in the judgment field to assign a weight for each word. This ensures that common words, also known as \"stop words\", found in the english language, like \"the\", \"a\", \"an\", etc., are weighted less than words that are unique for this dataset, such as \"foreign\", \"alcohol\", \"drugs\", etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up bag of words for judgment field, use english stop words\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(X.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '00065',\n",
       " '00141',\n",
       " '00360',\n",
       " '01293',\n",
       " '01366',\n",
       " '01378',\n",
       " '01727',\n",
       " '01830',\n",
       " '02049',\n",
       " '02646',\n",
       " '02656',\n",
       " '02679',\n",
       " '02732',\n",
       " '03384',\n",
       " '05176',\n",
       " '05361',\n",
       " '054',\n",
       " '05554',\n",
       " '05663',\n",
       " '05694',\n",
       " '06683',\n",
       " '07072',\n",
       " '07184',\n",
       " '078',\n",
       " '08',\n",
       " '08744',\n",
       " '09',\n",
       " '09152',\n",
       " '10',\n",
       " '100',\n",
       " '1001',\n",
       " '11',\n",
       " '111',\n",
       " '11379',\n",
       " '11772',\n",
       " '11940',\n",
       " '12',\n",
       " '120',\n",
       " '1200',\n",
       " '12153',\n",
       " '13',\n",
       " '130',\n",
       " '136',\n",
       " '14',\n",
       " '15',\n",
       " '153',\n",
       " '154',\n",
       " '16',\n",
       " '169',\n",
       " '17',\n",
       " '175',\n",
       " '18',\n",
       " '19',\n",
       " '1959',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1969',\n",
       " '1970',\n",
       " '1970s',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1978',\n",
       " '1979',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '199',\n",
       " '1990',\n",
       " '1990s',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2001',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '2010',\n",
       " '203',\n",
       " '20s',\n",
       " '21',\n",
       " '215',\n",
       " '22',\n",
       " '23',\n",
       " '235',\n",
       " '24',\n",
       " '25',\n",
       " '25th',\n",
       " '26',\n",
       " '263',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '300',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '335',\n",
       " '336',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '38',\n",
       " '39',\n",
       " '40',\n",
       " '401k',\n",
       " '41',\n",
       " '42',\n",
       " '421',\n",
       " '43',\n",
       " '435c',\n",
       " '44',\n",
       " '45',\n",
       " '471',\n",
       " '484',\n",
       " '49',\n",
       " '50',\n",
       " '500',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '548',\n",
       " '563',\n",
       " '568',\n",
       " '59',\n",
       " '60',\n",
       " '603',\n",
       " '616',\n",
       " '626',\n",
       " '63',\n",
       " '631',\n",
       " '632',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '685',\n",
       " '700',\n",
       " '704',\n",
       " '709',\n",
       " '71',\n",
       " '710',\n",
       " '72',\n",
       " '75',\n",
       " '760',\n",
       " '775',\n",
       " '80',\n",
       " '800',\n",
       " '81',\n",
       " '827',\n",
       " '83',\n",
       " '86',\n",
       " '88',\n",
       " '90',\n",
       " '91',\n",
       " '919',\n",
       " '94',\n",
       " '96',\n",
       " '970',\n",
       " 'a1',\n",
       " 'a10',\n",
       " 'a2',\n",
       " 'aa',\n",
       " 'ab',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abot',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absolutely',\n",
       " 'absolve',\n",
       " 'absolving',\n",
       " 'absorb',\n",
       " 'abstain',\n",
       " 'abstained',\n",
       " 'abstention',\n",
       " 'abstin',\n",
       " 'abstinence',\n",
       " 'abstinent',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abuses',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'ac',\n",
       " 'academic',\n",
       " 'accept',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accessing',\n",
       " 'accident',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'accrued',\n",
       " 'accruing',\n",
       " 'accumulated',\n",
       " 'acquaintances',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquittal',\n",
       " 'acquitted',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'ada',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addictions',\n",
       " 'addictive',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addressing',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adjudicate',\n",
       " 'adjudication',\n",
       " 'adjudications',\n",
       " 'adjudicative',\n",
       " 'adm',\n",
       " 'administ',\n",
       " 'administer',\n",
       " 'administered',\n",
       " 'administration',\n",
       " 'administrative',\n",
       " 'administratively',\n",
       " 'admissibility',\n",
       " 'admissions',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admitting',\n",
       " 'adoption',\n",
       " 'adulterated',\n",
       " 'adv',\n",
       " 'adver',\n",
       " 'advers',\n",
       " 'adverse',\n",
       " 'adversely',\n",
       " 'advised',\n",
       " 'aff',\n",
       " 'affect',\n",
       " 'affecting',\n",
       " 'affir',\n",
       " 'affirmatively',\n",
       " 'affirmed',\n",
       " 'afford',\n",
       " 'afghanistan',\n",
       " 'afraid',\n",
       " 'afte',\n",
       " 'aftercare',\n",
       " 'ag',\n",
       " 'age',\n",
       " 'agency',\n",
       " 'agents',\n",
       " 'aggravated',\n",
       " 'aggregate',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreements',\n",
       " 'aid',\n",
       " 'alc',\n",
       " 'alcoho',\n",
       " 'alcohol',\n",
       " 'alcoholics',\n",
       " 'alcoholism',\n",
       " 'alford',\n",
       " 'allegation',\n",
       " 'allegations',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'alleges',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'almist',\n",
       " 'alter',\n",
       " 'altercation',\n",
       " 'alternate',\n",
       " 'altho',\n",
       " 'amd',\n",
       " 'amend',\n",
       " 'american',\n",
       " 'amounting',\n",
       " 'amphetamine',\n",
       " 'amphetamines',\n",
       " 'amsterdam',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'anecdotal',\n",
       " 'annual',\n",
       " 'annually',\n",
       " 'anonymous',\n",
       " 'answer',\n",
       " 'answers',\n",
       " 'anticipate',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'apartme',\n",
       " 'appe',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appellant',\n",
       " 'appellate',\n",
       " 'appl',\n",
       " 'appli',\n",
       " 'appliance',\n",
       " 'applic',\n",
       " 'applicable',\n",
       " 'applican',\n",
       " 'applicant',\n",
       " 'applicantmitigated',\n",
       " 'applicants',\n",
       " 'applicat',\n",
       " 'applicati',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'appllicant',\n",
       " 'apply',\n",
       " 'appropriate',\n",
       " 'approval',\n",
       " 'approximate',\n",
       " 'approximately',\n",
       " 'april',\n",
       " 'ar',\n",
       " 'arab',\n",
       " 'arbitrary',\n",
       " 'argue',\n",
       " 'argues',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'arising',\n",
       " 'armenia',\n",
       " 'arose',\n",
       " 'arrangements',\n",
       " 'arrearages',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'arrests',\n",
       " 'article',\n",
       " 'articulate',\n",
       " 'asdc3i',\n",
       " 'assault',\n",
       " 'assaulted',\n",
       " 'assembler',\n",
       " 'asserted',\n",
       " 'assertion',\n",
       " 'assertions',\n",
       " 'assessed',\n",
       " 'assessing',\n",
       " 'assessment',\n",
       " 'assets',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'assisted',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'assumed',\n",
       " 'assuming',\n",
       " 'assumptions',\n",
       " 'attempted',\n",
       " 'attempts',\n",
       " 'attend',\n",
       " 'attendance',\n",
       " 'attended',\n",
       " 'attendi',\n",
       " 'attending',\n",
       " 'attends',\n",
       " 'attorney',\n",
       " 'attributable',\n",
       " 'attributed',\n",
       " 'august',\n",
       " 'authorities',\n",
       " 'authority',\n",
       " 'authorized',\n",
       " 'authorizing',\n",
       " 'automatic',\n",
       " 'automobile',\n",
       " 'available',\n",
       " 'averaged',\n",
       " 'averment',\n",
       " 'avers',\n",
       " 'avoid',\n",
       " 'awaits',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'awards',\n",
       " 'away',\n",
       " 'background',\n",
       " 'backing',\n",
       " 'bad',\n",
       " 'balance',\n",
       " 'balances',\n",
       " 'bank',\n",
       " 'bankrup',\n",
       " 'bankruptcies',\n",
       " 'bankruptcy',\n",
       " 'bar',\n",
       " 'bare',\n",
       " 'based',\n",
       " 'basing',\n",
       " 'basis',\n",
       " 'battery',\n",
       " 'bears',\n",
       " 'beca',\n",
       " 'beer',\n",
       " 'beers',\n",
       " 'befor',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behalf',\n",
       " 'behaved',\n",
       " 'behavior',\n",
       " 'behavioral',\n",
       " 'belgian',\n",
       " 'belief',\n",
       " 'believe',\n",
       " 'believes',\n",
       " 'benefit',\n",
       " 'benefits',\n",
       " 'bias',\n",
       " 'bills',\n",
       " 'binding',\n",
       " 'binge',\n",
       " 'binging',\n",
       " 'birth',\n",
       " 'bizarre',\n",
       " 'blackmail',\n",
       " 'bo',\n",
       " 'boar',\n",
       " 'board',\n",
       " 'bodies',\n",
       " 'body',\n",
       " 'bonding',\n",
       " 'born',\n",
       " 'borrowed',\n",
       " 'bot',\n",
       " 'bought',\n",
       " 'bound',\n",
       " 'boy',\n",
       " 'brandishing',\n",
       " 'break',\n",
       " 'brief',\n",
       " 'bright',\n",
       " 'brings',\n",
       " 'british',\n",
       " 'broadly',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'budget',\n",
       " 'building',\n",
       " 'burden',\n",
       " 'burdens',\n",
       " 'business',\n",
       " 'businesses',\n",
       " 'buy',\n",
       " 'cac',\n",
       " 'called',\n",
       " 'came',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'candid',\n",
       " 'candidate',\n",
       " 'candor',\n",
       " 'capricious',\n",
       " 'car',\n",
       " 'card',\n",
       " 'cards',\n",
       " 'care',\n",
       " 'career',\n",
       " 'carefully',\n",
       " 'carry',\n",
       " 'carrying',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'catastrophic',\n",
       " 'categories',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'causing',\n",
       " 'ceased',\n",
       " 'ceasing',\n",
       " 'ceo',\n",
       " 'certain',\n",
       " 'chairman',\n",
       " 'challenge',\n",
       " 'challenged',\n",
       " 'challenges',\n",
       " 'chance',\n",
       " 'chances',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'changing',\n",
       " 'chap',\n",
       " 'chapter',\n",
       " 'char',\n",
       " 'character',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'charges',\n",
       " 'charging',\n",
       " 'check',\n",
       " 'chemical',\n",
       " 'child',\n",
       " 'children',\n",
       " 'cho',\n",
       " 'chosen',\n",
       " 'chronic',\n",
       " 'church',\n",
       " 'cigarettes',\n",
       " 'circumstance',\n",
       " 'circumstances',\n",
       " 'circumstant',\n",
       " 'circumstantial',\n",
       " 'cite',\n",
       " 'cited',\n",
       " 'citizen',\n",
       " 'citizens',\n",
       " 'citizensh',\n",
       " 'citizenshi',\n",
       " 'citizenship',\n",
       " 'civil',\n",
       " 'cl',\n",
       " 'claim',\n",
       " 'claimed',\n",
       " 'claiming',\n",
       " 'claims',\n",
       " 'clarity',\n",
       " 'classifi',\n",
       " 'classifie',\n",
       " 'classified',\n",
       " 'cle',\n",
       " 'clea',\n",
       " 'clear',\n",
       " 'cleara',\n",
       " 'clearan',\n",
       " 'clearanc',\n",
       " 'clearance',\n",
       " 'clearances',\n",
       " 'clearly',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closing',\n",
       " 'closure',\n",
       " 'cloud',\n",
       " 'cocaine',\n",
       " 'code',\n",
       " 'coercion',\n",
       " 'coherent',\n",
       " 'collateral',\n",
       " 'collaterally',\n",
       " 'colleagues',\n",
       " 'collected',\n",
       " 'collection',\n",
       " 'college',\n",
       " 'columbia',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'coming',\n",
       " 'commencing',\n",
       " 'commission',\n",
       " 'commit',\n",
       " 'commitment',\n",
       " 'committed',\n",
       " 'committing',\n",
       " 'common',\n",
       " 'commonly',\n",
       " 'communications',\n",
       " 'community',\n",
       " 'company',\n",
       " 'compel',\n",
       " 'compl',\n",
       " 'complain',\n",
       " 'complete',\n",
       " 'completed',\n",
       " 'completing',\n",
       " 'completion',\n",
       " 'compliance',\n",
       " 'complicated',\n",
       " 'complications',\n",
       " 'complied',\n",
       " 'compliment',\n",
       " 'comply',\n",
       " 'computer',\n",
       " 'conceal',\n",
       " 'concealed',\n",
       " 'concealing',\n",
       " 'concealment',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concerning',\n",
       " 'concerns',\n",
       " 'conclude',\n",
       " 'concluded',\n",
       " 'concluding',\n",
       " 'conclusion',\n",
       " 'conclusions',\n",
       " 'conclusive',\n",
       " 'condit',\n",
       " 'conditi',\n",
       " 'condition',\n",
       " 'conditional',\n",
       " 'conditions',\n",
       " 'conduct',\n",
       " 'conducted',\n",
       " 'confession',\n",
       " 'confidenc',\n",
       " 'confidence',\n",
       " 'confidential',\n",
       " 'confined',\n",
       " 'confirmed',\n",
       " 'conflicting',\n",
       " 'conflicts',\n",
       " 'confront',\n",
       " 'confronted',\n",
       " 'confusion',\n",
       " 'conjunction',\n",
       " 'connection',\n",
       " 'connections',\n",
       " 'consequence',\n",
       " 'consequences',\n",
       " 'consider',\n",
       " 'considerable',\n",
       " 'consideration',\n",
       " 'considerations',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'consist',\n",
       " 'consistent',\n",
       " 'consistently',\n",
       " 'consisting',\n",
       " 'consolidate',\n",
       " 'consolidation',\n",
       " 'constitute',\n",
       " 'constitutes',\n",
       " 'constitutionality',\n",
       " 'construct',\n",
       " 'construction',\n",
       " 'construed',\n",
       " 'consume',\n",
       " 'consumed',\n",
       " 'consumer',\n",
       " 'consumers',\n",
       " 'consuming',\n",
       " 'consumption',\n",
       " 'contact',\n",
       " 'contacting',\n",
       " 'contacts',\n",
       " 'contain',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'contend',\n",
       " 'contending',\n",
       " 'contin',\n",
       " 'continuating',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'continues',\n",
       " 'continuing',\n",
       " 'continuous',\n",
       " 'contract',\n",
       " 'contractor',\n",
       " 'contradict',\n",
       " 'contradictory',\n",
       " 'contrary',\n",
       " 'contributed',\n",
       " 'contribution',\n",
       " 'contrite',\n",
       " 'control',\n",
       " 'controverted',\n",
       " 'convicted',\n",
       " 'conviction',\n",
       " 'convictions',\n",
       " 'convince',\n",
       " 'convinced',\n",
       " 'convinces',\n",
       " 'cooperation',\n",
       " 'copied',\n",
       " 'copyrighted',\n",
       " 'corporal',\n",
       " 'corporate',\n",
       " 'correct',\n",
       " 'correspondence',\n",
       " 'corroborate',\n",
       " 'corroborative',\n",
       " 'cost',\n",
       " 'counsel',\n",
       " 'counseling',\n",
       " 'counselor',\n",
       " 'counterfeiting',\n",
       " 'countries',\n",
       " 'country',\n",
       " 'counts',\n",
       " 'couple',\n",
       " 'coupled',\n",
       " 'course',\n",
       " 'court',\n",
       " 'courts',\n",
       " 'cousins',\n",
       " 'cover',\n",
       " 'covered',\n",
       " 'coworkers',\n",
       " 'cr',\n",
       " 'crack',\n",
       " 'crank',\n",
       " 'crash',\n",
       " 'created',\n",
       " 'cred',\n",
       " 'credentialed',\n",
       " 'credibility',\n",
       " 'credible',\n",
       " 'credibly',\n",
       " 'credit',\n",
       " 'credited',\n",
       " 'creditor',\n",
       " 'creditors',\n",
       " 'crime',\n",
       " 'crimes',\n",
       " 'criminal',\n",
       " 'criminally',\n",
       " 'criter',\n",
       " 'criterion',\n",
       " 'cross',\n",
       " 'crystal',\n",
       " 'culminated',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'custody',\n",
       " 'daily',\n",
       " 'damages',\n",
       " 'dangerous',\n",
       " 'dangers',\n",
       " 'data',\n",
       " 'date',\n",
       " 'dated',\n",
       " 'dating',\n",
       " 'daughter',\n",
       " 'daughters',\n",
       " 'day',\n",
       " 'days',\n",
       " 'dcf',\n",
       " 'deadline',\n",
       " 'dealing',\n",
       " 'death',\n",
       " 'deb',\n",
       " 'debt',\n",
       " 'debts',\n",
       " 'dec',\n",
       " 'decades',\n",
       " 'deceive',\n",
       " 'december',\n",
       " 'decemnber',\n",
       " 'deceptive',\n",
       " 'decide',\n",
       " 'decided',\n",
       " 'deciding',\n",
       " 'decisi',\n",
       " 'decision',\n",
       " 'decisions',\n",
       " 'decisive',\n",
       " 'declaration',\n",
       " 'declared',\n",
       " 'decline',\n",
       " 'declined',\n",
       " 'defaulted',\n",
       " 'defe',\n",
       " 'defect',\n",
       " 'defend',\n",
       " 'defendants',\n",
       " 'defense',\n",
       " 'deference',\n",
       " 'defraud',\n",
       " 'degree',\n",
       " 'del',\n",
       " 'delegated',\n",
       " 'deliberate',\n",
       " 'deliberately',\n",
       " 'delinquencies',\n",
       " 'delinquency',\n",
       " 'delinquent',\n",
       " 'demeanor',\n",
       " 'demo',\n",
       " 'demonstr',\n",
       " 'demonstrate',\n",
       " 'demonstrated',\n",
       " 'demonstratedquestionable',\n",
       " 'demonstrates',\n",
       " 'demonstrating',\n",
       " 'den',\n",
       " 'denial',\n",
       " 'denials',\n",
       " 'denied',\n",
       " 'denies',\n",
       " 'deny',\n",
       " 'department',\n",
       " 'dependence',\n",
       " 'dependency',\n",
       " 'dependent',\n",
       " 'deployments',\n",
       " 'depression',\n",
       " 'deprives',\n",
       " 'depth',\n",
       " 'derogatory',\n",
       " 'designed',\n",
       " 'desk',\n",
       " 'despite',\n",
       " 'destroy',\n",
       " 'destroyed',\n",
       " 'details',\n",
       " 'detained',\n",
       " 'detection',\n",
       " 'deteriorate',\n",
       " 'determination',\n",
       " 'determinations',\n",
       " 'determine',\n",
       " 'determining',\n",
       " 'detoxification',\n",
       " 'detracts',\n",
       " 'develo',\n",
       " 'develop',\n",
       " 'developing',\n",
       " 'deviate',\n",
       " 'deviates',\n",
       " 'device',\n",
       " 'devotion',\n",
       " 'diagnosed',\n",
       " 'diagnoses',\n",
       " 'diagnosis',\n",
       " 'did',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'difficulties',\n",
       " 'diminish',\n",
       " 'direction',\n",
       " 'directive',\n",
       " 'directly',\n",
       " 'director',\n",
       " 'dis',\n",
       " 'disagreement',\n",
       " 'disavow',\n",
       " 'disavowed',\n",
       " 'discern',\n",
       " 'discharge',\n",
       " 'discharged',\n",
       " 'discharging',\n",
       " 'disclose',\n",
       " 'disclosed',\n",
       " 'disclosure',\n",
       " 'discontinued',\n",
       " 'discount',\n",
       " 'discretion',\n",
       " 'discuss',\n",
       " 'dishonest',\n",
       " 'dishonesty',\n",
       " 'disintegrating',\n",
       " 'dismiss',\n",
       " 'dismissed',\n",
       " 'disorder',\n",
       " 'disparate',\n",
       " 'dispel',\n",
       " 'disposed',\n",
       " 'dispositive',\n",
       " 'disproving',\n",
       " 'dispute',\n",
       " 'disputed',\n",
       " 'disputes',\n",
       " 'disq',\n",
       " 'disqualifying',\n",
       " 'dissatisfaction',\n",
       " 'distant',\n",
       " 'distinction',\n",
       " 'distinguished',\n",
       " 'distribu',\n",
       " 'distribution',\n",
       " 'disturb',\n",
       " 'divorce',\n",
       " 'divorces',\n",
       " 'doctor',\n",
       " 'doctrine',\n",
       " 'documen',\n",
       " 'document',\n",
       " 'documentary',\n",
       " 'documentation',\n",
       " 'documented',\n",
       " 'documents',\n",
       " 'dod',\n",
       " 'does',\n",
       " 'doha',\n",
       " 'doing',\n",
       " 'domestic',\n",
       " 'doubt',\n",
       " 'doubts',\n",
       " 'downloaded',\n",
       " 'downturn',\n",
       " 'downturns',\n",
       " 'dr',\n",
       " 'drank',\n",
       " 'drawer',\n",
       " 'drawn',\n",
       " 'drink',\n",
       " 'drinker',\n",
       " 'drinkin',\n",
       " 'drinking',\n",
       " 'drinks',\n",
       " 'driving',\n",
       " 'drop',\n",
       " 'dropped',\n",
       " 'drug',\n",
       " 'drugs',\n",
       " 'drunk',\n",
       " 'drunkenness',\n",
       " 'du',\n",
       " 'dual',\n",
       " 'dui',\n",
       " 'duis',\n",
       " 'duration',\n",
       " 'duty',\n",
       " 'dwi',\n",
       " 'e2',\n",
       " 'eaja',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'earn',\n",
       " 'earned',\n",
       " 'earnings',\n",
       " 'education',\n",
       " 'eeo',\n",
       " 'effect',\n",
       " 'effective',\n",
       " 'effectively',\n",
       " 'effectuate',\n",
       " 'effort',\n",
       " 'efforts',\n",
       " 'eighteen',\n",
       " 'elderly',\n",
       " 'elected',\n",
       " 'elections',\n",
       " 'electronic',\n",
       " 'eligibility',\n",
       " 'eligible',\n",
       " 'em',\n",
       " 'emirates',\n",
       " ...]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print bag of words to ensure it is set up correctly\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our list created and number of occurrences counted and weighted appropriately, we need to ensure that the data is all accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2684 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ensure that data is in the right format - TfidfVectorizer returns sparse matrix of type <class numpy.float64>\n",
    "X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 2684)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure we have all records that were passed into the vectorizer\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set-up y: Fix Boolean Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our X values set up in a way that a machine learning algorithm can understand it, but now we need to fix our y values. In order to do this we need to change our true/false values into a numeric format. To do this, we need to change all true values to 1.0 and all false values to 0.0.\n",
    "\n",
    "Note how we are only taking the first 700 records for the y set because we only took the first 700 records for our X set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace: True = 1.0, False = 0.0\n",
    "y = y.replace(True,1).head(700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    356\n",
       "1.0    344\n",
       "Name: Denied, dtype: int64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print out counts for all y records - ensure that our replace statement worked\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Data Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our X and y are in the right format, we need to ensure one last time that the dimensions of each dataframe are correct. For our X, we see that there are 500 rows and 2,117 columns (different words in BOW). For our y, we see that there are 500 rows and no columns.\n",
    "\n",
    "Our data has passed the check and is ready to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 2684)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700,)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Machine Learning Step-by-Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Run train_test_split() on X & y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is not needed for this notebook but it shows you how the train_test_split function works. Our X and y are randomly split up into training and testing groups. In this case, our test group will be comprised of 33% of the X data(test_size), and will be the same each time we run this line (random_state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break 33% of X and y into X_test and y_test, break other remaining 67% into X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469, 2684)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print size of training data (335/500 = .67)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 2684)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print size of test data (165/500 = .33)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Run fit() on X_train & y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in our machine learning model is taking our training data and feeding it into an algorithm to build a model. This is essentially the step that teaches an algorithm that for each record X = y. To do this, there are a number of classification models. For this example we will focus on the LogisticRegression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify which classifier to use and set parameters\n",
    "clf = LogisticRegression(random_state=0, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send X and y into our classifier to build a model\n",
    "logreg_model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#print out all information about our model\n",
    "print(logreg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Run predict() on X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in our process is to take the model we just made using the training data and feeding the test data into it. This will output an array of values that the algorithm has determined to be the denied status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send our test data into the model we just created\n",
    "y_pred = logreg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the model's predictions: \n",
      "[1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#print our results for the predictions\n",
    "print(\"Here is the model's predictions: \")\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Verify Accuracy of Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have split our data into training and testing groups, created a model using a machine learning algorithm, and used the model to predict outcomes for our test data, it is time to verify how well our model did compared to the actual outcomes. To do this, there are a number of accuracy metrics. For this example we will focus on the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import our score functions\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for LogisticRegression classifier:   0.8441558441558441\n"
     ]
    }
   ],
   "source": [
    "#compare y_test values with the predicted y values\n",
    "score = accuracy_score(y_test, y_pred).mean()\n",
    "print(\"Accuracy score for LogisticRegression classifier:  \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Here we can see that our LogisticRegression model was correct 84.42% of the time when predicting the denied status from the judgment field alone.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test for Best Algorithm to Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand how machine learning is done, we can determine which model is the best choice for our data. In this example we will use 5 different classifiers and evaluate each against 5 accuracy metrics.\n",
    "\n",
    "__Note:__ \n",
    "1. For picking a fold size, it is recommended to choose n=5, 10, or 20 (http://vinhkhuc.github.io/2015/03/01/how-many-folds-for-cross-validation.html). For this problem, we have chosen K = 20 and the comparisons can be found at https://github.com/mawebster9/ThesisCode/blob/master/NumFoldsComparison.txt.\n",
    "2. The cross_val_score() function works by running all of the following functions:\n",
    "    - Shuffle the dataset randomly\n",
    "    - Split the dataset into k (n=20) groups\n",
    "        - For each unique group:\n",
    "        - Take the group as a hold out or test data set\n",
    "        - Take the remaining groups as a training data set\n",
    "        - Fit a model on the training set and evaluate it on the test set\n",
    "        - Retain the evaluation score and discard the model\n",
    "    - Summarize the skill of the model using the sample of model evaluation scores\n",
    "    \n",
    "__The cross_val_score() function is essentially an all-in-one function.__\n",
    "\n",
    "3. For the scoring metrics:\n",
    "    - __roc_auc:__ The area under a ROC Curve (plots the fraction of _true positives out of the positives (TPR = true positive rate) vs. the fraction of false positives out of the negatives (FPR = false positive rate))_\n",
    "    - __f_1:__ The weighted average of Precision and Recall _(F1 = 2 * ((precision * recall) / (precision + recall)))_\n",
    "    - __accuracy:__ A ratio of correctly predicted observation to the total observations _(Accuracy = (TruePositives+TrueNegatives)/(TruePositives+FalsePositives+FalseNegatives+TrueNegatives))_\n",
    "    - __precision:__ The ability of the classifier to not label negative samples as positive _(Precision = TruePositives/(TruePositives+FalsePositives))_\n",
    "    - __recall:__ The ability of the classifier to find all positive samples _(Recall = TruePositives/(TruePositives+FalseNegatives))_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------\n",
      "Classifier:  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=5,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "\n",
      "Scoring Metrics: \n",
      "\t* roc_auc score:  0.8308428382246145\n",
      "\t* f1 score:  0.7653262462701783\n",
      "\t* accuracy score:  0.7610364145658264\n",
      "\t* precision score:  0.726615353962978\n",
      "\t* recall score:  0.7996732026143791\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Classifier:  GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "\n",
      "Scoring Metrics: \n",
      "\t* roc_auc score:  0.7362881263616556\n",
      "\t* f1 score:  0.7405972527106925\n",
      "\t* accuracy score:  0.7369561157796451\n",
      "\t* precision score:  0.740146952720482\n",
      "\t* recall score:  0.7503267973856209\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Classifier:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "Scoring Metrics: \n",
      "\t* roc_auc score:  0.8984407706437697\n",
      "\t* f1 score:  0.8213369307550625\n",
      "\t* accuracy score:  0.8098366013071896\n",
      "\t* precision score:  0.7941392775611041\n",
      "\t* recall score:  0.8630718954248368\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Classifier:  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "\n",
      "Scoring Metrics: \n",
      "\t* roc_auc score:  0.7368464052287581\n",
      "\t* f1 score:  0.747305478231814\n",
      "\t* accuracy score:  0.7266573295985059\n",
      "\t* precision score:  0.7581969264451766\n",
      "\t* recall score:  0.7410130718954246\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Classifier:  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n",
      "                     weights='uniform')\n",
      "\n",
      "Scoring Metrics: \n",
      "\t* roc_auc score:  0.8541175402622923\n",
      "\t* f1 score:  0.7670202071542204\n",
      "\t* accuracy score:  0.7681909430438841\n",
      "\t* precision score:  0.7781400476850739\n",
      "\t* recall score:  0.766830065359477\n"
     ]
    }
   ],
   "source": [
    "classifiers = [RandomForestClassifier(n_estimators=5), GaussianNB(), LogisticRegression(solver='liblinear'), DecisionTreeClassifier(criterion='gini'), KNeighborsClassifier(n_neighbors=6)]\n",
    "clf_names = ['RandomForest','GausianNB','LogisticRegression','DecisionTreeClassRegressor', 'KNeighbors']\n",
    "metric_names = ['roc_auc','f1','accuracy','precision','recall']\n",
    "\n",
    "scv = StratifiedKFold(n_splits=20)\n",
    "\n",
    "scores_df = pd.DataFrame(index=metric_names,columns=clf_names)\n",
    "clf_scores = []\n",
    "for clf, name in zip(classifiers, clf_names):\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print('Classifier: ',clf)\n",
    "    print('')\n",
    "    print(\"Scoring Metrics: \")\n",
    "    for metric in metric_names:\n",
    "        score = cross_val_score(clf,X.toarray(),y,scoring=metric, cv=scv).mean()\n",
    "        clf_scores.append(score)\n",
    "        print('\\t*',metric,'score: ', score)\n",
    "    scores_df[name] = clf_scores\n",
    "    clf_scores = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For text classification, the top performing machine learning algorithm is LogisticRegression. This classifier works by analyzing a dataset with one or more independent variables that determine an outcome - the outcome is measured with a binary variable (only 2 outcomes possible)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The accuracy_score for LogisticRegression is different in sections 4 and 5 because in section 4 the function was only run once whereas in section 5 it was run 20 times and averaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
